{
  "hash": "78a8df7395293e90762b442903b5a51d",
  "result": {
    "markdown": "---\ntitle: \"Timeseries classification from scratch\"\nauthors:\n  - \"[hfawaz](https://github.com/hfawaz/)\"\n  - \"[terrytangyuan](https://github.com/terrytangyuan) - R adaptation\"\n  - \"[t-kalinowski](https://github.com/t-kalinowski) - R adaptation\"\ndate-created: 2022/12/03\ndate-last-modified: 2022/12/03\ndescription: \"Training a timeseries classifier from scratch on the FordA dataset from the UCR/UEA archive.\"\ncategories: [timeseries]\naliases:\n  - ../guide/keras/examples/timeseries_classification_from_scratch/index.html\n---\n\n\n## Introduction\n\nThis example shows how to do timeseries classification from scratch,\nstarting from raw CSV timeseries files on disk. We demonstrate the\nworkflow on the FordA dataset from the [UCR/UEA\narchive](https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/).\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\nlibrary(keras)\nset.seed(1234)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA\"\n\ntrain_df <- \"FordA_TRAIN.tsv\" %>%\n  get_file(., file.path(url, .)) %>%\n  readr::read_tsv(col_names = FALSE)\nx_train <- as.matrix(train_df[, -1])\ny_train <- as.matrix(train_df[, 1])\n\ntest_df <- \"FordA_TEST.tsv\" %>%\n  get_file(., file.path(url, .)) %>%\n  readr::read_tsv(col_names = FALSE)\nx_test <- as.matrix(test_df[, -1])\ny_test <- as.matrix(test_df[, 1])\n```\n:::\n\n\n## Visualize the data\n\nHere we visualize one timeseries example for each class in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggfortify)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n```{.r .cell-code}\nautoplot(ts(tibble::tibble(\n  \"Class -1\" = x_train[1, ],\n  \"Class 1\" = x_train[2, ]\n)), ts.geom = 'line', facets = FALSE)\n```\n\n::: {.cell-output-display}\n![](timeseries_classification_from_scratch_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Standardize the data\n\nOur timeseries are already in a single length (500). However, their\nvalues are usually in various ranges. This is not ideal for a neural\nnetwork; in general we should seek to make the input values normalized.\nFor this specific dataset, the data is already z-normalized: each\ntimeseries sample has a mean equal to zero and a standard deviation\nequal to one. This type of normalization is very common for timeseries\nclassification problems, see [Bagnall et al.\n(2016)](https://link.springer.com/article/10.1007/s10618-016-0483-9).\n\nIn order to use `sparse_categorical_crossentropy`, we will have to count\nthe number of classes beforehand.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(num_classes <- length(unique(y_train)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\nNow we shuffle the training set because we will be using the\n`validation_split` option later when training.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshuffle_ind <- sample(nrow(x_train))\nx_train <- x_train[shuffle_ind, ]\ny_train <- y_train[shuffle_ind, ]\n```\n:::\n\n\nStandardize the labels to positive integers. The expected labels will\nthen be 0 and 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny_train[y_train == -1] <- 0\ny_test[y_test == -1] <- 0\n```\n:::\n\n\nNote that the timeseries data used here are univariate, meaning we only\nhave one channel per timeseries example. We will therefore transform the\ntimeseries into a multivariate one with one channel using a simple\nreshaping. This will allow us to construct a model that is easily\napplicable to multivariate time series.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add channel dim of size 1\ndim(x_train) <- c(dim(x_train), 1)\ndim(x_test) <- c(dim(x_test), 1)\n```\n:::\n\n\n## Build a model\n\nWe build a Fully Convolutional Neural Network originally proposed in\n[this paper](https://arxiv.org/abs/1611.06455). The implementation is\nbased on the TF 2 version provided\n[here](https://github.com/hfawaz/dl-4-tsc/). The following\nhyperparameters (kernel_size, filters, the usage of BatchNorm) were\nfound via random search using\n[KerasTuner](https://github.com/keras-team/keras-tuner).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninput_shape <- dim(x_train)[-1] # drop batch dim\ninput_layer <- layer_input(input_shape)\n\noutput_layer <- input_layer %>%\n\n  # First convolutional layer\n  layer_conv_1d(64, 3, padding = \"same\") %>%\n  layer_batch_normalization() %>%\n  layer_activation_relu() %>%\n\n  # Second convolutional layer\n  layer_conv_1d(64, 3, padding = \"same\") %>%\n  layer_batch_normalization() %>%\n  layer_activation_relu() %>%\n\n  # Third convolutional layer\n  layer_conv_1d(64, 3, padding = \"same\") %>%\n  layer_batch_normalization() %>%\n  layer_activation_relu() %>%\n\n  layer_global_average_pooling_1d() %>%\n  layer_dense(num_classes, activation = \"softmax\")\n\nmodel <- keras_model(input_layer, output_layer)\n```\n:::\n\n\n## Train the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepochs <- 300\nbatch_size <- 32\ncallbacks <- list(\n  callback_model_checkpoint(\"best_model.h5\", monitor = \"val_loss\",\n                            save_best_only = TRUE),\n  callback_reduce_lr_on_plateau(monitor = \"val_loss\", factor = 0.5,\n                                patience = 20, min_lr = 0.0001),\n  callback_early_stopping(monitor = \"val_loss\", patience = 50,\n                          verbose = 1)\n)\n\nmodel %>% compile(\n  optimizer = \"adam\",\n  loss = \"sparse_categorical_crossentropy\",\n  metrics = list(\"sparse_categorical_accuracy\")\n)\n\nhistory <- model %>%\n  fit(x_train, y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_split = 0.2,\n    verbose = 1)\n```\n:::\n\n\n## Evaluate model on test data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloaded_model <- load_model_hdf5(\"best_model.h5\")\nresult <- loaded_model %>% evaluate(x_test, as.matrix(y_test))\n\nsprintf(\"Test loss: %s\", result[[\"loss\"]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Test loss: 0.103852786123753\"\n```\n:::\n\n```{.r .cell-code}\nsprintf(\"Test accuracy: %s\", result[[\"sparse_categorical_accuracy\"]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Test accuracy: 0.966666638851166\"\n```\n:::\n:::\n\n\n## Plot the model's training and validation loss\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(history)\n```\n\n::: {.cell-output-display}\n![](timeseries_classification_from_scratch_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWe can see how the training accuracy reaches almost 0.95 after 100\nepochs. However, by observing the validation accuracy we can see how the\nnetwork still needs training until it reaches almost 0.97 for both the\nvalidation and the training accuracy after 200 epochs. Beyond the 200th\nepoch, if we continue on training, the validation accuracy will start\ndecreasing while the training accuracy will continue on increasing: the\nmodel starts overfitting.\n",
    "supporting": [
      "timeseries_classification_from_scratch_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}