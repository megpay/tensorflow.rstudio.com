{
  "hash": "b5b322c9e6ccfe018a3fa2f49106a308",
  "result": {
    "markdown": "---\ntitle: \"Getting Started with tfautograph\"\ndescription: >\n  Learn how you can use R control flow expressions like `if`, `while` and \n  `for` with TensorFlow, in both eager and graph modes.\n---\n\n\n\n\nThe R function `tfautograph::autograph()` helps you write TensorFlow\ncode using R control flow. It allows you to use tensors in R control\nflow expressions like `if`, `while`, and `for`, which can automatically\nbe translated to build a tensorflow graph (hence the name, **auto**\n**graph**).\n\nThis guide goes through some of the main features and then goes into how\nit works a little.\n\nBefore we get started a clarification: The R package {tfautograph} is\ninspired by the functionality (and name) of the `tf.autograph` submodule\nin the python interface to Tensorflow, but it has little relation to\nthat code base. If you're interested in writing Tensorflow code in R\nusing native R syntax, then keep reading because you're in the right\nplace. If you're looking for an interface to the `tf.autograph` Python\nsubmodule from the R, this is probably not what you're looking for.\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nlibrary(tensorflow)\nlibrary(tfdatasets)\n\nlibrary(tfautograph)\n```\n:::\n\n\n## Compatibility\n\ntfautograph works with Tensorflow versions 1.15 and \\>= 2.0. This guide\nis rendered using version 2.11.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntf_config()\n## TensorFlow v2.11.0 (~/.virtualenvs/r-tensorflow-website/lib/python3.10/site-packages/tensorflow)\n## Python v3.10 (~/.virtualenvs/r-tensorflow-website/bin/python)\n```\n:::\n\n\n# Usage\n\nThe primary workhorse that enables usage of control flow in\n`tf_function()` is `tfautograph::autograph()`. For most use-cases, you\nwill not need to call `autograph()` directly, it is automatically\ninvoked when calling `tf_function(fn, autograph = TRUE)`, (the default).\nHowever, you can also invoke it directly. It can either take a function\nor an expression. The following two uses are equivalent:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pass a function to autograph()\nfn <- function(x) if(x > 0) x * x else x\nsquare_if_positive <- autograph(fn)\n\n# pass an expression to autograph()\nsquare_if_positive <- function(x) autograph(if(x > 0) x * x else x)\n```\n:::\n\n\nNow `square_if_positive()` is a function that can accept a tensor as an\nargument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- tf$convert_to_tensor(5)\ny <- tf$convert_to_tensor(-5)\nsquare_if_positive(x)\n## tf.Tensor(25.0, shape=(), dtype=float32)\nsquare_if_positive(y)\n## tf.Tensor(-5.0, shape=(), dtype=float32)\n```\n:::\n\n\nNote that if you're in a context where TensorFlow is executing eagerly,\n`autograph()` doesn't change that--`square_if_positive()` is still\nexecuting eagerly. You can test that by inserting some R `message()`\ncalls to see when a branch is evaluated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsquare_if_positive_verbose <- autograph(function(x) {\n  if (x > 0) {\n    message(\"Evaluating true branch\")\n    x * x\n  } else {\n    message(\"Evaluating false branch\")\n    x\n  }\n})\n\nsquare_if_positive_verbose(x)\n## Evaluating true branch\n## tf.Tensor(25.0, shape=(), dtype=float32)\nsquare_if_positive_verbose(x)\n## Evaluating true branch\n## tf.Tensor(25.0, shape=(), dtype=float32)\nsquare_if_positive_verbose(x)\n## Evaluating true branch\n## tf.Tensor(25.0, shape=(), dtype=float32)\n\nsquare_if_positive_verbose(y)\n## Evaluating false branch\n## tf.Tensor(-5.0, shape=(), dtype=float32)\nsquare_if_positive_verbose(y)\n## Evaluating false branch\n## tf.Tensor(-5.0, shape=(), dtype=float32)\nsquare_if_positive_verbose(y)\n## Evaluating false branch\n## tf.Tensor(-5.0, shape=(), dtype=float32)\n```\n:::\n\n\nAs you can see we're in eager mode, meaning, the R code of the function\nbody is evaluated every time the function is called.\n\nThe easiest way to enter a context where TensorFlow is not executing\neagerly anymore and instead is in **graph mode** is to call\n`tf_function()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngraph_fn <- tf_function(square_if_positive_verbose)\n\ngraph_fn(x)\n## Evaluating true branch\n## Evaluating false branch\n## tf.Tensor(25.0, shape=(), dtype=float32)\ngraph_fn(x)\n## tf.Tensor(25.0, shape=(), dtype=float32)\ngraph_fn(x)\n## tf.Tensor(25.0, shape=(), dtype=float32)\n\ngraph_fn(y)\n## tf.Tensor(-5.0, shape=(), dtype=float32)\ngraph_fn(y)\n## tf.Tensor(-5.0, shape=(), dtype=float32)\ngraph_fn(y)\n## tf.Tensor(-5.0, shape=(), dtype=float32)\n```\n:::\n\n\nIn graph mode, both branches of the `if` expression are traced into a\nTensorFlow graph the first time the function is called and the resultant\ngraph is cached by TensorFlow `Function` object returned from\n`tf_function()`. Then on subsequent calls of the `Function`, only the\ncached graph is evaluated.\n\nThe key takeaways are that `autograph()` helps you write natural R code\nand use tensors in expressions where R wouldn't otherwise accept them.\nAnd that `autograph()` is smart enough to do the right thing in both\neager mode and graph mode.\n\n# Control Flow\n\ntfautograph can translate R control flow statements `if`, `while`,\n`for`, `break`, and `next` to tensorflow. Here is summary table of the\ntranslation endpoints (note, these summary code snippets are meant to\nconcisely convey the spirit of the translation, not the actual\nimplementation)\n\n| R expression          | Graph Mode Translation | Eager Mode Translation                              |\n|-----------------------|------------------------|-----------------------------------------------------|\n| `if(x)`               | `tf$cond(x, ...)`      | `` if(x$`__bool__`()) ``                            |\n| `while(x)`            | `tf$while_loop(...)`   | `while(as.logical(x))`                              |\n| `for(x in tensor)`    | `tf$while_loop(...)`   | `while(!is.null(x <- iter_next(tensor_iterator)))`  |\n| `for(x in tfdataset)` | `dataset_reduce()`     | `while(!is.null(x <- iter_next(dataset_iterator)))` |\n\nLets go through them one at a time.\n\n## `if`\n\nIn eager mode, `if(eager_tensor)` is translated to\n`` if(eager_tensor$`__bool__`()) ``. (Equivalent to calling\n`reticulate::py_bool()`, and in essence a slightly more robust way to\ncall `as.logical(eager_tensor)`).\n\nIn graph mode, `if` statements written in R automatically get translated\nto a `tf.cond()`. `tf.cond()` requires that both branches of the\nconditional are balanced (meaning, both branches return the same output\nstructure). `autograph()` tries to capture all locally modified\nvariables, newly created variables, as well as the return value of the\noverall expression in the translated `tf.cond()`, while satisfying the\nrequirement for balanced branches.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntf_sign <- tf_function(function(x) {\n  if (x > 0)\n    1\n  else if (x < 0)\n    -1\n  else\n    0\n})\n```\n:::\n\n\nAny variables that can't be balanced between the branches are exported\nas **undefined** objects (S3 class: `undef`). Undefined objects throw an\ninformative error if you attempt to access them. The error message\nindicates which expression the `undef` originated from, and suggestions\nfor how to prevent the symbol from being an `undef`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nundef_example <- tf_function(function(x) {\n  if (x > 0) {\n    branch_local_tmp <- x + 1\n    x <- branch_local_tmp + 1\n    x\n  }\n  branch_local_tmp\n})\nundef_example(tf$constant(1))\n## Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: Evaluation error: Symbol `branch_local_tmp` is *undefined* after autographing the expression:\n##  \tif (x > 0) {\n## \t    branch_local_tmp <- x + 1\n## \t    x <- branch_local_tmp + 1\n## \t    x\n## \t}\n## To access this symbol, Tensorflow requires that an object with the same dtype and shape be assigned to the symbol either before the `if` statement, or in all branches of the `if` statement.\n```\n:::\n\n\n## `while`\n\nIn eager mode, `while(eagor_tensor)` is translated to\n`while(as.logical(eager_tensor))`. The `tensorflow` R package provides\ntensor methods for many S3 generics, including `as.logical()` which\ncoerces an `EagerTensor` to an R logical atomic, so this works as you\nwould expect.\n\nHere is an example of an autographed `while` expression being evaluated\neagerly. Remember, `autograph()` is not just for functions!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal <- 1\nx\n## tf.Tensor(5.0, shape=(), dtype=float32)\nautograph({\n  while (x != 0) {\n    message(\"Evaluating while body R expression\")\n    total %<>% multiply_by(x)\n    x %<>% subtract(tf_sign(x))\n  }\n})\n## Evaluating while body R expression\n## Evaluating while body R expression\n## Evaluating while body R expression\n## Evaluating while body R expression\n## Evaluating while body R expression\nx\n## tf.Tensor(0.0, shape=(), dtype=float32)\ntotal\n## tf.Tensor(120.0, shape=(), dtype=float32)\n```\n:::\n\n\nIn graph mode, `while` expressions are translated to a `tf$while_loop()`\ncall.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntf_factorial <- tf_function(autograph(function(x) {\n  total <- 1\n  while (x != 0) {\n    message(\"Evaluating while body R expression\")\n    total %<>% multiply_by(x)\n    x %<>% subtract(tf_sign(x))\n  }\n  total\n}))\n\ntf_factorial(tf$constant(5))\n## Evaluating while body R expression\n## tf.Tensor(120.0, shape=(), dtype=float32)\ntf_factorial(tf$constant(-5))\n## tf.Tensor(-120.0, shape=(), dtype=float32)\n```\n:::\n\n\n[`tf.while_loop()`](https://www.tensorflow.org/api_docs/python/tf/while_loop)\nhas many options. In order to pass those through to the call, precede\nthe `while` expression with `ag_while_opts()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntf_factorial_v2 <- tf_function(function(x) {\n  total <- as_tensor(1, dtype = x$dtype)\n  ag_while_opts(\n    shape_invariants = list(total = shape(), x = shape()),\n    parallel_iterations = 1\n  )\n  while (x != 0) {\n    message(\"Evaluating while body R expression\")\n    total %<>% multiply_by(x)\n    x %<>% subtract(tf_sign(x))\n  }\n  total\n})\ntf_factorial_v2(tf$constant(5))\n## Evaluating while body R expression\n## tf.Tensor(120.0, shape=(), dtype=float32)\n```\n:::\n\n\n## `for`\n\nAutographed `for` loops build on top of while loops. `autograph()` adds\nsupport for three new types of values passed to `for`:\n\n-   TF Datasets\n-   Tensors\n-   Python iterators (eager mode only).\n\nIn eager mode, both Datasets and Tensors are coerced to iterators (via\n`reticulate::as_iterator()`). The arguments are then iterated over until\nthe iterable is finished. Essentially, a call like\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(elem in iterable) {...}\n```\n:::\n\n\ngets translated to\n\n\n::: {.cell}\n\n```{.r .cell-code}\niterator <- as_iterator(iterable)\nwhile(!iter_is_done(iterator)) {elem <- iter_next(iterator); ...}\n```\n:::\n\n\nNote, tensors are iterated over their first dimension.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- tf$convert_to_tensor(matrix(1:12, nrow = 3, byrow = TRUE))\nm\n## tf.Tensor(\n## [[ 1  2  3  4]\n##  [ 5  6  7  8]\n##  [ 9 10 11 12]], shape=(3, 4), dtype=int32)\nautograph({\n  for (row in m)\n    print(row)\n})\n## tf.Tensor([1 2 3 4], shape=(4), dtype=int32)\n## tf.Tensor([5 6 7 8], shape=(4), dtype=int32)\n## tf.Tensor([ 9 10 11 12], shape=(4), dtype=int32)\n```\n:::\n\n\nIn graph mode, `for` can accept a Tensor or a Dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nniave_reduce_sum <- tf_function(function(x, dtype = \"int64\") {\n  running_total <- tf$zeros(list(), dtype)\n  for (elem in x)\n    running_total %<>% add(elem)\n\n  running_total\n})\n```\n:::\n\n\nWorks with a Tensor:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nniave_reduce_sum(tf$range(10L, dtype = \"int64\"))\n## tf.Tensor(45, shape=(), dtype=int64)\n```\n:::\n\n\nand with a Dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nniave_reduce_sum(tf$data$Dataset$range(10L))\n## tf.Tensor(45, shape=(), dtype=int64)\n```\n:::\n\n\nSince `for(var in tensor)` loops are powered by `tf$while_loop()`, you\ncan pass additional options via `ag_while_opts()` just as you would to\nan autographed `while()` expression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nniave_reduce_sum_with_opts <- tf_function(autograph(function(x) {\n  running_total <- tf$zeros(list(), x$dtype)\n\n  ag_while_opts(parallel_iterations = 1)\n  for (elem in x)\n    running_total %<>% add(elem)\n\n  running_total\n}))\n\nniave_reduce_sum_with_opts(tf$range(10))\n## tf.Tensor(45.0, shape=(), dtype=float32)\n```\n:::\n\n\n## `break` / `next`\n\nLoop control flow statements `break` and `next` are handled\nautomatically by `autograph()`, both in eager mode and graph mode. Use\n`break` and/or `next` anywhere you would use it naturally in `while` and\n`for` loops.\n\n# FizzBuzz!\n\nLets tie some concepts together to write\n[fizzbuzz](https://en.wikipedia.org/wiki/Fizz_buzz)! Before we do that,\nwe'll write a helper `tf_print()` that writes to a temporary file by\ndefault. This will help knitr capture the output in this quarto\ndocument. (If we don't redirect output to a file, then it would show up\nin the rendering console and not in this vignette)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTEMPFILE <- tempfile(\"tf-print-out\", fileext = \".txt\")\n\nprint_tempfile <-\n  function(clear_after_read = TRUE, rewrap_lines = TRUE) {\n    output <- readLines(TEMPFILE, warn = FALSE)\n    if (clear_after_read) unlink(TEMPFILE)\n    if (rewrap_lines) output <- strwrap(paste0(output, collapse = \" \"))\n    writeLines(output)\n  }\n\ntf_print <- function(...)\n  tf$print(..., output_stream = sprintf(\"file://%s\", TEMPFILE))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfizzbuzz <- autograph(function(n) {\n  for (i in range_dataset(from = 1L, to = n)) {\n    if (i %% 15L == 0L)\n      tf_print(\"FizzBuzz\")\n    else if (i %% 3L == 0L)\n      tf_print(\"Fizz\")\n    else if (i %% 5L == 0L)\n     tf_print(\"Buzz\")\n    else\n      tf_print(i)\n  }\n})\n```\n:::\n\n\nFirst, lets run it in eager mode.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfizzbuzz(tf$constant(25L))\nprint_tempfile()\n## 1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz 16 17\n## Fizz 19 Buzz Fizz 22 23 Fizz\n```\n:::\n\n\nAnd now in graph mode.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntf_fizzbuzz <- tf_function(fizzbuzz)\ntf_fizzbuzz(tf$constant(25L))\nprint_tempfile()\n## 1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz 16 17\n## Fizz 19 Buzz Fizz 22 23 Fizz\n```\n:::\n\n\n# Visualize Function Graphs\n\nAs you are writing `tf.function()`s, it's helpful to visualize what the\nproduced graph from a particular autographed function looks like. Use\n`tfautograph::view_function_graph()` to launch a tensorboard instance\nwith the produced function graph from a temporary directory. Note, the\nfunction must be being traced for the first time for\n`view_function_graph` to succeed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nview_function_graph(tf_function(fizzbuzz), list(tf$constant(25L)))\n```\n:::\n\n\n![FizzBuzz Graph in\nTensorboard](images/fizzbuzz-graph-in-tensorboard.png){style=\"width\"}\n\n\n::: {.cell}\n\n:::\n\n\n## Control Dependencies\n\nSide effects Ops `tf$print()` and `tf$Assert()` created within a\n`tf_function` are executed in-line and in the correct order when the\nfunction is evaluated. (If you're used to working Tensorflow version 1,\nyou read that right!)\n\nTensorflow 2 has drastically changed (for the better!) how control\ndependencies work. For the most part, so long as you only enter graph\nmode while within a `tf_function()`, there is no need anymore to enter a\ncontrol dependency context. The days of wrapping code in a\n`with(tf$control_dependency(...), ...)` are mostly over.\n\n<!-- If you're still working in Tensorflow version 1, check out the vignette  on TF v1 and control dependencies. In particular, `autograph()` does  some cool tricks to help enter and exit a `tf$control_dependency()` context when autographing `stopifnot()`. -->\n\n# Growing Objects / TensorArrays\n\nThe package provides a `[[<-` method for TensorArrays. That's the\nrecommended way to grow objects on the graph. See\n`` ?`[[<-.tensorflow.python.ops.tensor_array_ops.TensorArray` `` for\nusage examples.\n\n# Other helpers\n\nThe tfautograph package provides a small collection of additional\nhelpers when working with tensorflow from R. They are:\n\n-   `tf_assert()`: A thin wrapper around `tf.Assert()` that\n    automatically generates a useful error message that includes the R\n    call stack and the values of the tensors involved in the assert\n    expression.\n-   `tf_cond()`, `tf_case()`, `tf_switch()`: Thin wrappers around the\n    control flow primitives that accept compact (`rlang` style \\~)\n    lambda syntax for the callables.\n\n# How it works\n\n`autograph()` works by evaluating expressions in an environment where\nprimitives like `if` and `for` are masked by autographing versions of\nthem. The complete list of which symbols are masked by `autograph()` is:\n\n\n::: {.cell}\n\n```\n## [1] \"if\"        \"while\"     \"for\"       \"break\"     \"next\"      \"stopifnot\"\n## [7] \"on.exit\"\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}